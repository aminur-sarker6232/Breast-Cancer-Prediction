{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZOY_pTyYhMA7"
      },
      "source": [
        "# Import Library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eL98Slu2hMBA"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_f1GxCzbhMBC"
      },
      "source": [
        "# Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H0pWk4rlhMBD"
      },
      "outputs": [],
      "source": [
        "df=pd.read_csv(r\"https://raw.githubusercontent.com/azaz6216/dataset/refs/heads/main/data%20-%20Copy.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GVS0NcpnhMBD"
      },
      "source": [
        "# EDA (Exploratory Data Analysis)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "notebookRunGroups": {
          "groupValue": "1"
        },
        "id": "bOrUd3WuhMBE"
      },
      "source": [
        "### a. Understanding the Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qxuz6f0xhMBE"
      },
      "source": [
        "- Head of the dataset\n",
        "- Shape of the data set\n",
        "- Types of columns\n",
        "- Information about data set\n",
        "- Summary of the data set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UEkCGgiWhMBF"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9VOC1_B2hMBG"
      },
      "outputs": [],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3x0TZO-2hMBH"
      },
      "outputs": [],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "19NpT0wUhMBH"
      },
      "outputs": [],
      "source": [
        "df.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PSH-w-3VhMBI"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZRgOpCzDhMBI"
      },
      "outputs": [],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zMabpk79hMBI"
      },
      "source": [
        "### b. Cleaning the Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h4J8Hvb5hMBJ"
      },
      "source": [
        "- Dropping duplicate values\n",
        "- Checking NULL values\n",
        "- Checking for 0 value and replacing it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AMO8weBRhMBJ"
      },
      "outputs": [],
      "source": [
        "df = df.drop_duplicates()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4uWcvJlkhMBJ"
      },
      "outputs": [],
      "source": [
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1B5Ntyn3hMBK"
      },
      "source": [
        "### Checking for specified value occurance in feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fJzxnOFIhMBK"
      },
      "outputs": [],
      "source": [
        "x=(df==0).sum()\n",
        "x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iy5Q7oQLhMBK"
      },
      "source": [
        "### Fill the zero"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b8QMD7zChMBL"
      },
      "outputs": [],
      "source": [
        "for col in df.columns:\n",
        "    if df[col].dtype != 'object' and col != 'diagnosis':\n",
        "        df[col] = df[col].replace(0, np.NaN)\n",
        "        mean_val = df[col].mean(skipna=True)\n",
        "        df[col] = df[col].replace(np.NaN, mean_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mZVB1MJihMBL"
      },
      "outputs": [],
      "source": [
        "y=(df==0).sum()\n",
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vdgNS69mhMBL"
      },
      "outputs": [],
      "source": [
        "v=df.isnull().sum()\n",
        "v"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WakiLThhhMBL"
      },
      "source": [
        "### Drop unneccessary columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y2sd28KRhMBM"
      },
      "outputs": [],
      "source": [
        "df=df.drop([\"id\"],axis=1)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3-PYQXiZhMBM"
      },
      "outputs": [],
      "source": [
        "df=df.dropna(axis=1)\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XiyLw8XrhMBM"
      },
      "source": [
        "### Convert object type to int type(diagnosis)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4s1_MSFShMBM"
      },
      "outputs": [],
      "source": [
        "df['diagnosis'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DwfX2iOohMBM"
      },
      "outputs": [],
      "source": [
        "sns.countplot(x=\"diagnosis\",data=df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ahqsIFg5hMBN"
      },
      "outputs": [],
      "source": [
        "data=df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xplnHLDAhMBN"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EE2E93yDhMBN"
      },
      "outputs": [],
      "source": [
        "lb=LabelEncoder()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kfhw62VyhMBO"
      },
      "outputs": [],
      "source": [
        "data['diagnosis']=lb.fit_transform(data[\"diagnosis\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "chJ8L-ZOhMBO"
      },
      "outputs": [],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Cfc_xhShMBO"
      },
      "outputs": [],
      "source": [
        "data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LmF6gU3ihMBO"
      },
      "outputs": [],
      "source": [
        "data['diagnosis'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sjpf1YtWhMBP"
      },
      "outputs": [],
      "source": [
        "sns.countplot(x=\"diagnosis\",data=data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cOERkuA6hMBQ"
      },
      "source": [
        "# Data Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5z5evxQDhMBQ"
      },
      "outputs": [],
      "source": [
        "data.hist(bins=31,figsize=(20,20))\n",
        "plt.show"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cEfoOyNChMBW"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(20,24))\n",
        "sns.set_style(style='whitegrid')\n",
        "\n",
        "plt.subplot(6,5,1)\n",
        "sns.boxplot(x='radius_mean',data=data)\n",
        "plt.subplot(6,5,2)\n",
        "sns.boxplot(x='texture_mean',data=data)\n",
        "plt.subplot(6,5,3)\n",
        "sns.boxplot(x='perimeter_mean',data=data)\n",
        "plt.subplot(6,5,4)\n",
        "sns.boxplot(x='area_mean',data=data)\n",
        "plt.subplot(6,5,5)\n",
        "sns.boxplot(x='smoothness_mean',data=data)\n",
        "\n",
        "plt.subplot(6,5,6)\n",
        "sns.boxplot(x='compactness_mean',data=data)\n",
        "plt.subplot(6,5,7)\n",
        "sns.boxplot(x='concavity_mean',data=data)\n",
        "plt.subplot(6,5,8)\n",
        "sns.boxplot(x='concave points_mean',data=data)\n",
        "plt.subplot(6,5,9)\n",
        "sns.boxplot(x='symmetry_mean',data=data)\n",
        "plt.subplot(6,5,10)\n",
        "sns.boxplot(x='fractal_dimension_mean',data=data)\n",
        "\n",
        "plt.subplot(6,5,11)\n",
        "sns.boxplot(x='radius_se',data=data)\n",
        "plt.subplot(6,5,12)\n",
        "sns.boxplot(x='texture_se',data=data)\n",
        "plt.subplot(6,5,13)\n",
        "sns.boxplot(x='perimeter_se',data=data)\n",
        "plt.subplot(6,5,14)\n",
        "sns.boxplot(x='area_se',data=data)\n",
        "plt.subplot(6,5,15)\n",
        "sns.boxplot(x='smoothness_se',data=data)\n",
        "\n",
        "plt.subplot(6,5,16)\n",
        "sns.boxplot(x='compactness_se',data=data)\n",
        "plt.subplot(6,5,17)\n",
        "sns.boxplot(x='concavity_se',data=data)\n",
        "plt.subplot(6,5,18)\n",
        "sns.boxplot(x='concave points_se',data=data)\n",
        "plt.subplot(6,5,19)\n",
        "sns.boxplot(x='symmetry_se',data=data)\n",
        "plt.subplot(6,5,20)\n",
        "sns.boxplot(x='fractal_dimension_se',data=data)\n",
        "\n",
        "plt.subplot(6,5,21)\n",
        "sns.boxplot(x='radius_worst',data=data)\n",
        "plt.subplot(6,5,22)\n",
        "sns.boxplot(x='texture_worst',data=data)\n",
        "plt.subplot(6,5,23)\n",
        "sns.boxplot(x='perimeter_worst',data=data)\n",
        "plt.subplot(6,5,24)\n",
        "sns.boxplot(x='area_worst',data=data)\n",
        "plt.subplot(6,5,25)\n",
        "sns.boxplot(x='smoothness_worst',data=data)\n",
        "\n",
        "plt.subplot(6,5,26)\n",
        "sns.boxplot(x='compactness_worst',data=data)\n",
        "plt.subplot(6,5,27)\n",
        "sns.boxplot(x='concavity_worst',data=data)\n",
        "plt.subplot(6,5,28)\n",
        "sns.boxplot(x='concave points_worst',data=data)\n",
        "plt.subplot(6,5,29)\n",
        "sns.boxplot(x='symmetry_worst',data=data)\n",
        "plt.subplot(6,5,30)\n",
        "sns.boxplot(x='fractal_dimension_worst',data=data)\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6vB1cZslhMBW"
      },
      "outputs": [],
      "source": [
        "from pandas.plotting import scatter_matrix\n",
        "scatter_matrix(data,figsize=(50,50),color='red')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GxEvlkKNhMBX"
      },
      "source": [
        "# Feature Selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0FXSuGohMBX"
      },
      "source": [
        "Pearson's Correlation Coefficient : Helps you find out the relationship between two quantities. It gives you the measure of the strength of association between two variables. The value of Pearson's Correlation Coefficient can be between -1 to +1. 1 means that they are highly correlated and 0 means no correlation.\n",
        "\n",
        "A heat map is a two-dimensional representation of information with the help of colors. Heat maps can help the user visualize simple or complex information."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bd2lAFqfhMBX"
      },
      "outputs": [],
      "source": [
        "data.corr()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mjSPzhQihMBX"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "sns.heatmap(data.iloc[:,0:10].corr(),annot=True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gS1e0cPdhMBX"
      },
      "source": [
        "### Measure Importance of Feature using KBest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eA1AryQ6hMBY"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import chi2\n",
        "X = data.drop(['diagnosis'],axis = 1)\n",
        "y = data['diagnosis']\n",
        "bestfeatures = SelectKBest(score_func=chi2, k=30)\n",
        "fit = bestfeatures.fit(X,y)\n",
        "dfscores = pd.DataFrame(fit.scores_)\n",
        "dfcolumns = pd.DataFrame(X.columns)\n",
        "featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
        "featureScores.columns = ['Specs','Score']\n",
        "print(featureScores.nlargest(30,'Score'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KLK8Oi_DhMBY"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "model = ExtraTreesClassifier()\n",
        "model.fit(X,y)\n",
        "print(model.feature_importances_)\n",
        "feat_importances = pd.Series(model.feature_importances_, index=X.columns)\n",
        "feat_importances.nlargest(30).plot(kind='barh')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kvUHrT9yhMBY"
      },
      "source": [
        "# Handling Outliers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tNrj9QXlhMBY"
      },
      "source": [
        "### Outliers removal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ukVb1nRUhMBY"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import QuantileTransformer\n",
        "x=data.drop(['diagnosis'],axis=1)\n",
        "quantile  = QuantileTransformer(n_quantiles=569)\n",
        "w=quantile.fit_transform(x)\n",
        "data_new=pd.DataFrame(w,columns=x.columns)\n",
        "data_new['diagnosis'] = data['diagnosis'].values\n",
        "\n",
        "data_new.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gq3MyYlhhMBY"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(20,24))\n",
        "sns.set_style(style='whitegrid')\n",
        "\n",
        "plt.subplot(6,5,1)\n",
        "sns.boxplot(x='radius_mean',data=data_new)\n",
        "plt.subplot(6,5,2)\n",
        "sns.boxplot(x='texture_mean',data=data_new)\n",
        "plt.subplot(6,5,3)\n",
        "sns.boxplot(x='perimeter_mean',data=data_new)\n",
        "plt.subplot(6,5,4)\n",
        "sns.boxplot(x='area_mean',data=data_new)\n",
        "plt.subplot(6,5,5)\n",
        "sns.boxplot(x='smoothness_mean',data=data_new)\n",
        "\n",
        "plt.subplot(6,5,6)\n",
        "sns.boxplot(x='compactness_mean',data=data_new)\n",
        "plt.subplot(6,5,7)\n",
        "sns.boxplot(x='concavity_mean',data=data_new)\n",
        "plt.subplot(6,5,8)\n",
        "sns.boxplot(x='concave points_mean',data=data_new)\n",
        "plt.subplot(6,5,9)\n",
        "sns.boxplot(x='symmetry_mean',data=data_new)\n",
        "plt.subplot(6,5,10)\n",
        "sns.boxplot(x='fractal_dimension_mean',data=data_new)\n",
        "\n",
        "plt.subplot(6,5,11)\n",
        "sns.boxplot(x='radius_se',data=data_new)\n",
        "plt.subplot(6,5,12)\n",
        "sns.boxplot(x='texture_se',data=data_new)\n",
        "plt.subplot(6,5,13)\n",
        "sns.boxplot(x='perimeter_se',data=data_new)\n",
        "plt.subplot(6,5,14)\n",
        "sns.boxplot(x='area_se',data=data_new)\n",
        "plt.subplot(6,5,15)\n",
        "sns.boxplot(x='smoothness_se',data=data_new)\n",
        "\n",
        "plt.subplot(6,5,16)\n",
        "sns.boxplot(x='compactness_se',data=data_new)\n",
        "plt.subplot(6,5,17)\n",
        "sns.boxplot(x='concavity_se',data=data_new)\n",
        "plt.subplot(6,5,18)\n",
        "sns.boxplot(x='concave points_se',data=data_new)\n",
        "plt.subplot(6,5,19)\n",
        "sns.boxplot(x='symmetry_se',data=data_new)\n",
        "plt.subplot(6,5,20)\n",
        "sns.boxplot(x='fractal_dimension_se',data=data_new)\n",
        "\n",
        "plt.subplot(6,5,21)\n",
        "sns.boxplot(x='radius_worst',data=data_new)\n",
        "plt.subplot(6,5,22)\n",
        "sns.boxplot(x='texture_worst',data=data_new)\n",
        "plt.subplot(6,5,23)\n",
        "sns.boxplot(x='perimeter_worst',data=data_new)\n",
        "plt.subplot(6,5,24)\n",
        "sns.boxplot(x='area_worst',data=data_new)\n",
        "plt.subplot(6,5,25)\n",
        "sns.boxplot(x='smoothness_worst',data=data_new)\n",
        "\n",
        "plt.subplot(6,5,26)\n",
        "sns.boxplot(x='compactness_worst',data=data_new)\n",
        "plt.subplot(6,5,27)\n",
        "sns.boxplot(x='concavity_worst',data=data_new)\n",
        "plt.subplot(6,5,28)\n",
        "sns.boxplot(x='concave points_worst',data=data_new)\n",
        "plt.subplot(6,5,29)\n",
        "sns.boxplot(x='symmetry_worst',data=data_new)\n",
        "plt.subplot(6,5,30)\n",
        "sns.boxplot(x='fractal_dimension_worst',data=data_new)\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nRBGpPJshMBZ"
      },
      "outputs": [],
      "source": [
        "sns.pairplot(data_new,hue=\"diagnosis\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Sx-oFO7hMBZ"
      },
      "source": [
        "#  Split Dataset for dependent and independent Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VvAWlE9dhMBa"
      },
      "outputs": [],
      "source": [
        "X=data_new.drop(['diagnosis'],axis=1)\n",
        "y=data_new['diagnosis']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mupduij_hMBa"
      },
      "outputs": [],
      "source": [
        "X.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aLSR1lBihMBa"
      },
      "outputs": [],
      "source": [
        "y.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jw3E1WbqhMBa"
      },
      "source": [
        "# Train Test Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z83cJkZ3hMBb"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s71PX8IahMBb"
      },
      "source": [
        "## Standard Scaling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FUpc8l9-hMBb"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "st=StandardScaler()\n",
        "X_train=st.fit_transform(X_train)\n",
        "X_test=st.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X3xPOmFEhMBb"
      },
      "source": [
        "# Cross Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dBqYeEb0hMBc"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import KFold, cross_val_score\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "models ={\n",
        "    'Decision Tree':DecisionTreeClassifier(),\n",
        "    'Random Forest': RandomForestClassifier(),\n",
        "    'KNN': KNeighborsClassifier(),\n",
        "    'Logistic Regression': LogisticRegression(),\n",
        "    'SVM' : SVC()\n",
        "}\n",
        "k_fold = KFold(n_splits = 7, shuffle=True, random_state = 42)\n",
        "\n",
        "for model_name, model in models.items():\n",
        "    cross_score = cross_val_score(model, X, y, cv=k_fold)\n",
        "    print(f\"--------------------------------------------------------\")\n",
        "    print(f\"{model_name}:\\n\")\n",
        "    print(f\"Cross Validation Score for each fold:{cross_score}\\n\")\n",
        "    print(f\"Average Cross Validation Score: {cross_score.mean()}\\n\")\n",
        "    print(f\"--------------------------------------------------------\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1ksqo3bhMBc"
      },
      "source": [
        "# Classification Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EAyoJlu2hMBc"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC\n",
        "sv=SVC(probability=True)\n",
        "sv.fit(X_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fq1rpje2hMBd"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WQSfkqZihMBd"
      },
      "outputs": [],
      "source": [
        "print(classification_report(sv.predict(X_test),y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p9OB98_ghMBd"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score\n",
        "from sklearn.model_selection import GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HJ4bFpUchMBd"
      },
      "outputs": [],
      "source": [
        "knn= KNeighborsClassifier()\n",
        "n_neighbors = list(range(15,25))\n",
        "p=[1,2]\n",
        "weights = ['uniform', 'distance']\n",
        "metric = ['euclidean', 'manhattan', 'minkowski']\n",
        "hyperparameters = dict(n_neighbors=n_neighbors, p=p,weights=weights,metric=metric)\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "grid_search = GridSearchCV(estimator=knn, param_grid=hyperparameters, n_jobs=-1, cv=cv, scoring='f1',error_score=0)\n",
        "best_model = grid_search.fit(X_train,y_train)\n",
        "\n",
        "#Best Hyperparameters Value\n",
        "print('Best leaf_size:', best_model.best_estimator_.get_params()['leaf_size'])\n",
        "print('Best p:', best_model.best_estimator_.get_params()['p'])\n",
        "print('Best n_neighbors:', best_model.best_estimator_.get_params()['n_neighbors'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h8PNdfhqhMBd"
      },
      "outputs": [],
      "source": [
        "knn_pred = best_model.predict(X_test)\n",
        "print(\"Classification Report is:\\n\",classification_report(y_test,knn_pred))\n",
        "print(\"\\n F1:\\n\",f1_score(y_test,knn_pred))\n",
        "print(\"\\n Precision score is:\\n\",precision_score(y_test,knn_pred))\n",
        "print(\"\\n Recall score is:\\n\",recall_score(y_test,knn_pred))\n",
        "print(\"\\n Confusion Matrix:\\n\")\n",
        "sns.heatmap(confusion_matrix(y_test,knn_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TDimcLbJhMBe"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "lg=LogisticRegression()\n",
        "lg.fit(X_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TihLi91OhMBe"
      },
      "outputs": [],
      "source": [
        "print(classification_report(lg.predict(X_test),y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "laAw6TOJhMBe"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "tr=DecisionTreeClassifier(random_state=42)\n",
        "tr.fit(X_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dZMR4OvKhMBf"
      },
      "outputs": [],
      "source": [
        "print(classification_report(tr.predict(X_test),y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KhkZpaERhMBf"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rfc = RandomForestClassifier()\n",
        "rfc.fit(X_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5dIMUfdrhMBf"
      },
      "outputs": [],
      "source": [
        "print(classification_report(rfc.predict(X_test),y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rlLfSeh-hMBf"
      },
      "source": [
        "# Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kN4BBzu7hMBg"
      },
      "source": [
        "### Random forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WcAD4mnwhMBh"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [5, 10, 15],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(estimator=rfc, param_grid=param_grid,\n",
        "                           cv=5, n_jobs=-1, verbose=2)\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(f\"Best parameters found: {grid_search.best_params_}\")\n",
        "\n",
        "best_rfc_model = grid_search.best_estimator_\n",
        "\n",
        "y_pred_rfc = best_rfc_model.predict(X_test)\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred_rfc)}\")\n",
        "\n",
        "print(confusion_matrix(y_test, y_pred_rfc))\n",
        "\n",
        "print(classification_report(y_test, y_pred_rfc))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Ec4IulYhMBh"
      },
      "source": [
        "### SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bIlVhHAhhMBi"
      },
      "outputs": [],
      "source": [
        "param_grid = {\n",
        "    'C': [0.1, 1, 10, 100, 1000],\n",
        "    'gamma': [0.0001, 0.001, 0.01, 0.1, 1],\n",
        "    'kernel': ['linear', 'rbf', 'poly'],\n",
        "    'degree': [3, 4, 5]\n",
        "}\n",
        "grid_search = GridSearchCV(estimator=sv, param_grid=param_grid,\n",
        "                           cv=5, n_jobs=-1, verbose=2)\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(f\"Best parameters found: {grid_search.best_params_}\")\n",
        "\n",
        "best_svm_model = grid_search.best_estimator_\n",
        "\n",
        "y_pred_svm = best_svm_model.predict(X_test)\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "print(f\"Accuracy: {accuracy_score(y_test,y_pred_svm)}\")\n",
        "\n",
        "print(confusion_matrix(y_test, y_pred_svm))\n",
        "\n",
        "print(classification_report(y_test, y_pred_svm))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-q8KJF3MhMBi"
      },
      "source": [
        "### Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZtsKv0-ShMBi"
      },
      "outputs": [],
      "source": [
        "param_grid = {\n",
        "    'criterion': ['gini', 'entropy'],\n",
        "    'max_depth': [None, 10, 20, 30, 40],\n",
        "    'min_samples_split': [2, 10, 20],\n",
        "    'min_samples_leaf': [1, 5, 10],\n",
        "    'max_features': [None, 'sqrt', 'log2'],\n",
        "    'class_weight': [None, 'balanced']\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(estimator=tr, param_grid=param_grid,\n",
        "                           cv=5, n_jobs=-1, verbose=2)\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(f\"Best parameters found: {grid_search.best_params_}\")\n",
        "\n",
        "best_dt_model = grid_search.best_estimator_\n",
        "\n",
        "y_pred_dt = best_dt_model.predict(X_test)\n",
        "\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred_dt)}\")\n",
        "\n",
        "print(confusion_matrix(y_test,y_pred_dt))\n",
        "\n",
        "print(classification_report(y_test, y_pred_dt))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PdGGqO8shMBi"
      },
      "source": [
        "### Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V5j95lnahMBj"
      },
      "outputs": [],
      "source": [
        "\n",
        "param_grid = {\n",
        "    'C': [0.01, 0.1, 1, 10, 100],\n",
        "    'penalty': ['l1', 'l2', 'elasticnet'],\n",
        "    'solver': ['liblinear', 'saga'],\n",
        "    'class_weight': [None, 'balanced'],\n",
        "    'l1_ratio': [0, 0.5, 1]\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(estimator=lg, param_grid=param_grid,\n",
        "                           cv=5, n_jobs=-1, verbose=2)\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(f\"Best parameters found: {grid_search.best_params_}\")\n",
        "\n",
        "best_logreg_model = grid_search.best_estimator_\n",
        "\n",
        "y_pred_lr = best_logreg_model.predict(X_test)\n",
        "\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred_lr)}\")\n",
        "print(confusion_matrix(y_test,y_pred_lr))\n",
        "print(classification_report(y_test, y_pred_lr))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ywz4KtjjhMBj"
      },
      "source": [
        "### Bar chart for different algorithm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZGJAbURRhMBj"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_scores = [\n",
        "    accuracy_score(y_test, y_pred_svm),\n",
        "    accuracy_score(y_test, y_pred_lr),\n",
        "    accuracy_score(y_test, y_pred_dt),\n",
        "    accuracy_score(y_test, knn_pred),\n",
        "    accuracy_score(y_test, y_pred_rfc)\n",
        "]\n",
        "\n",
        "model_names = ['SVM','Logistic Regression', 'Decision Tree',  'KNN', 'Random Forest']\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "bars = plt.bar(model_names, accuracy_scores, color=['blue', 'green', 'orange', 'red', 'purple'])\n",
        "\n",
        "\n",
        "plt.title('Accuracy Scores of Different Models', fontsize=14)\n",
        "plt.xlabel('Models', fontsize=12)\n",
        "plt.ylabel('Accuracy Score', fontsize=12)\n",
        "\n",
        "for bar in bars:\n",
        "    height = bar.get_height()\n",
        "    plt.text(\n",
        "        bar.get_x() + bar.get_width() / 2.0,\n",
        "        height,\n",
        "        f'{height:.2%}',\n",
        "        ha='center', va='bottom', fontsize=12\n",
        "    )\n",
        "\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}